{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7900cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e078c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from Local_Library import data_prep, kalman_filter, data_prep_arima, data_prep_svr, arch_volatility_predictor, svr_predictor\n",
    "from Local_Library import garch_volatility_predictor, LSTM_predictor, arima_predictor\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7c69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 2 \n",
    "ETF_df = pd.read_csv('ETF_df.csv').iloc[-252*years:,111] # Selecting the latest two years of ETF data to test ML models.\n",
    "ETF_data = ETF_df.dropna() # Removing missing values.\n",
    "ETF_returns_df = ETF_data.pct_change() # Estimating % returns.\n",
    "ETF_returns_data = pd.Series(ETF_returns_df) # Converting ETF data to series format.\n",
    "window = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf946b4",
   "metadata": {},
   "source": [
    "## ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b06bca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data = data_prep(ETF_returns_data, 'Actual_Return', window, dropna=True, scale=True) # Preparing data structures for ARCH model.\n",
    "prep_data['X_train_var_arch'] = prep_data['X_train'].apply(lambda x: arch_volatility_predictor(x)) # Applying ARCH model on each row of the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e1316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data['X_train_var_arch_filtered'] = kalman_filter(prep_data['X_train_var_arch'].values) # Applying kalman filter to de-noise the data.\n",
    "X_train_var_adjusted = prep_data['X_train_var'][1:] # Adjusting for prediction shift.\n",
    "X_train_var_arch_filtered_adjusted = prep_data['X_train_var_arch_filtered'][:-1] # Adjusting for prediction shift.\n",
    "prep_data_adjusted = pd.DataFrame(list(zip(\n",
    "    X_train_var_adjusted, X_train_var_arch_filtered_adjusted)), columns=['X_train_var_adjusted', \n",
    "                                                                         'X_train_var_arch_filtered_adjusted']) # Storing required information in a data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fac30ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCH RMSE: 0.21754894029590177\n",
      "ARCH MAE: 0.15266819126055295\n"
     ]
    }
   ],
   "source": [
    "print('ARCH RMSE:', np.sqrt(mean_squared_error(prep_data_adjusted[['X_train_var_adjusted']], \n",
    "                                               prep_data_adjusted[['X_train_var_arch_filtered_adjusted']]))) # Calculating and printing ARCH rmse.\n",
    "\n",
    "print('ARCH MSE:', mean_squared_error(prep_data_adjusted[['X_train_var_adjusted']], \n",
    "                                               prep_data_adjusted[['X_train_var_arch_filtered_adjusted']])) # Calculating and printing ARCH mse.\n",
    "\n",
    "print('ARCH MAE:', np.mean(np.abs(prep_data_adjusted['X_train_var_adjusted'] -\n",
    "                                  prep_data_adjusted['X_train_var_arch_filtered_adjusted']))) # Calculating and printing ARCH mae.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_plot = prep_data_adjusted[['X_train_var_adjusted','X_train_var_arch_filtered_adjusted']].plot(figsize=(12,4)); # Printing real and estimated volatility.\n",
    "arch_plot.legend(['Actual', 'Predicted'])\n",
    "arch_plot.figure.savefig('arch_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ceaded",
   "metadata": {},
   "source": [
    "## GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data_garch = data_prep(ETF_returns_data, 'Actual_Return', window, dropna=True, scale=True) # Preparing data structures for GARCH model.\n",
    "prep_data_garch['X_train_var_garch'] = prep_data_garch['X_train'].apply(lambda x: garch_volatility_predictor(x)) # Applying GARCH model on each row of the prepared data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11048841",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data_garch['X_train_var_garch_filtered'] = kalman_filter(prep_data_garch['X_train_var_garch'].values) # Applying kalman filter to de-noise the data.\n",
    "X_train_var_adjusted = prep_data_garch['X_train_var'][1:] # Adjusting for prediction shift.\n",
    "X_train_var_arch_filtered_adjusted = prep_data_garch['X_train_var_garch_filtered'][:-1] # Adjusting for prediction shift.\n",
    "prep_data_adjusted = pd.DataFrame(list(zip(\n",
    "    X_train_var_adjusted, X_train_var_arch_filtered_adjusted)), columns=['X_train_var_adjusted', \n",
    "                                                                         'X_train_var_garch_filtered_adjusted']) # Storing required information in a data frame.\n",
    "print('GARCH RMSE:', np.sqrt(mean_squared_error(prep_data_adjusted[['X_train_var_adjusted']], \n",
    "                                               prep_data_adjusted[['X_train_var_garch_filtered_adjusted']]))) # Calculating and printing GARCH rmse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "garch_plot = prep_data_adjusted[['X_train_var_adjusted','X_train_var_garch_filtered_adjusted']].plot(figsize=(12,4)); # Printing real and estimated volatility.\n",
    "garch_plot.legend(['Actual', 'Predicted'])\n",
    "garch_plot.figure.savefig('garch_plot.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc9114",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ba3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_lstm  = data_prep_arima(ETF_returns_data, 'Actual_Return', \n",
    "                                'Actual_Variance', window, dropna=True, scale=True) # Preparing data structures for LSTM model.\n",
    "input_shape = (window, 1) # Shape of the input data based on volatility window length.\n",
    "# Instantiating the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "lstm_model.add(LSTM(50, return_sequences=False))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "data_df_lstm[\"Predicted_Variance\"] = data_df_lstm[[\n",
    "    'X_train','y_train','X_test']].apply(lambda x: LSTM_predictor(\n",
    "    lstm_model, x['X_train'],x['y_train'],x['X_test'])[0][0], axis=1) # Applying LSTM model on each row of the prepared data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LSTM RMSE:', np.sqrt(mean_squared_error(data_df_lstm[['y_test']], \n",
    "                                               data_df_lstm[['Predicted_Variance']]))) # Calculating and printing LSTM rmse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3da04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_plot = data_df_lstm[['y_test','Predicted_Variance']].plot(figsize=(12,4)); # Printing real and estimated volatility.lst\n",
    "lstm_plot.legend(['Actual', 'Predicted'])\n",
    "lstm_plot.figure.savefig('lstm_plot.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726189b",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 22\n",
    "prep_data_svr  = data_prep_svr(ETF_returns_data, 'Actual_Return', \n",
    "                               'Actual_Variance', window, dropna=True, scale=True) # Preparing data structures for SVR model.\n",
    "# Instantiating the SVR model\n",
    "svr_model = SVR(kernel='rbf', C=1000, gamma=0.1)\n",
    "\n",
    "prep_data_svr[\"Predicted_Variance\"] = prep_data_svr[[\n",
    "    'X_train','y_train','X_test']].apply(lambda x: svr_predictor(\n",
    "    svr_model, x['X_train'],x['y_train'],x['X_test'])[0], axis=1) # Applying SVR model on each row of the prepared data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de2976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_adjusted = [x[0] for x in prep_data_svr.y_test.values] # Extracting test data which is used for SVR model analysis.\n",
    "y_predicted = prep_data_svr['Predicted_Variance'] # Extracting predicted data which is used for SVR model analysis.\n",
    "\n",
    "prep_data_svr_adjusted = pd.DataFrame(list(zip(\n",
    "    y_test_adjusted, y_predicted)), columns=['y_test_adjusted','y_predicted']) # Storing required information in a data frame.\n",
    "print('SVR RMSE:', np.sqrt(mean_squared_error(prep_data_svr_adjusted[['y_test_adjusted']], \n",
    "                                               prep_data_svr_adjusted[['y_predicted']]))) # Calculating and printing LSTM rmse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_plot = prep_data_svr_adjusted[['y_test_adjusted',\"y_predicted\"]].plot(figsize=(12,4)); # Printing real and estimated volatility.\n",
    "svr_plot.legend(['Actual', 'Predicted'])\n",
    "svr_plot.figure.savefig('svr_plot.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e7e74",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad814432",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 22\n",
    "prep_data_arima = data_prep_arima(ETF_returns_data, 'Actual_Return', \n",
    "                                  'Actual_Variance', window, dropna=True, scale=True) # Preparing data structures for ARIMA model.\n",
    "\n",
    "prep_data_arima[\"Predicted_Variance\"] = prep_data_arima[\n",
    "    'X_train'].apply(lambda x: arima_predictor(x)[0]) # Applying ARIMA model on each row of the prepared data.\n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe61ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ARIMA RMSE:', np.sqrt(mean_squared_error(prep_data_arima[['y_test']],\n",
    "                                                                prep_data_arima[['Predicted_Variance']]))) # Calculating and printing ARIMA rmse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_plot = prep_data_arima[['y_test','Predicted_Variance']].plot(figsize=(12,4)); # Printing real and estimated volatility.\n",
    "arima_plot.legend(['Actual', 'Predicted'])\n",
    "arima_plot.figure.savefig('arima_plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24461f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
